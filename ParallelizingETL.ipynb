{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ParallelizingETL.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM5EzgX/Pqpii6se/GnNfsw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dorisratego/TensorFlowML-AI/blob/main/ParallelizingETL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewfeHych74rk"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import multiprocessing"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPzajlA78WAk"
      },
      "source": [
        "#Get dataset\n",
        "train_data = tfds.load('cats_vs_dogs', split='train', with_info=True)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOvpYtjR9AuF"
      },
      "source": [
        "#create a list of these files and use tf.Data.Dataset.list_files to load them\n",
        "file_pattern = f'/root/tensorflow_datasets/cats_vs_dogs/4.0.0/cats_vs_dogs-train.tfrecord*'\n",
        "files = tf.data.Dataset.list_files(file_pattern)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OUrfMVq9kZQ"
      },
      "source": [
        "#load files into a dataset using files.interleave\n",
        "train_dataset = files.interleave(\n",
        "                     tf.data.TFRecordDataset, \n",
        "                     cycle_length=4, #specify the number of parallel calls to execute\n",
        "                     num_parallel_calls=tf.data.experimental.AUTOTUNE # number of parallel calls based on number of CPU\n",
        "                )"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PB7pEpc-DuPe"
      },
      "source": [
        "#create the mapping function that loads the raw TFRecord and converts it to usable content\n",
        "def read_tfrecord(serialized_example):\n",
        "  feature_description={\n",
        "      \"image\": tf.io.FixedLenFeature((), tf.string, \"\"),\n",
        "      \"label\": tf.io.FixedLenFeature((), tf.int64, -1),\n",
        "  }\n",
        "  example = tf.io.parse_single_example(\n",
        "       serialized_example, feature_description\n",
        "  )\n",
        "  image = tf.io.decode_jpeg(example['image'], channels=3)\n",
        "  image = tf.cast(image, tf.float32)\n",
        "  image = image / 255\n",
        "  image = tf.image.resize(image, (300,300))\n",
        "  return image, example['label']\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7BTfaCZFbdR",
        "outputId": "24f915c2-0365-4a1c-8706-b65cd637ff49"
      },
      "source": [
        "#calling the mapping function to parallelize the transformation of data\n",
        "cores = multiprocessing.cpu_count()\n",
        "print(cores)\n",
        "train_dataset = train_dataset.map(read_tfrecord, num_parallel_calls=cores)\n",
        "train_dataset = train_dataset.cache() #cache the dataset in memory."
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UoymV9PGHpN"
      },
      "source": [
        "#parallelizing Loading and training\n",
        "train_dataset = train_dataset.shuffle(1024).batch(32)\n",
        "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "id": "l5jXXEqgGXUW",
        "outputId": "362d2d01-66a9-42c9-c791-7a19aa06e5cc"
      },
      "source": [
        "#train model\n",
        "model.fit(train_dataset, epochs=10, verbose=1)\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-1a85cf474574>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    }
  ]
}